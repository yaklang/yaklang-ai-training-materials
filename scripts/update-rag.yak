#!/usr/bin/env yak

// =============================================================================
// RAG å¢é‡æ›´æ–°å·¥å…· - Update RAG with Diff ZIP
// åŠŸèƒ½: è¯»å–å·®å¼‚ ZIP åŒ…ï¼Œæ›´æ–° RAG çŸ¥è¯†åº“ï¼Œæ”¯æŒä½¿ç”¨ embedding æœåŠ¡
// ç”¨é€”: å¢é‡æ›´æ–° RAG ç´¢å¼•ã€è‡ªåŠ¨åŒ–çŸ¥è¯†åº“æ›´æ–°ã€CI/CD é›†æˆ
//
// æ ¸å¿ƒæŠ€æœ¯æ ˆ:
// - rag.Import/Export: RAG å¯¼å…¥å¯¼å‡º
// - rag.Get: è·å– RAG é›†åˆ
// - zip.Recursive/ExtractFile: ZIP æ–‡ä»¶å¤„ç†
// - twofa.GetUTCCode: TOTP éªŒè¯
// - poc.HTTP: HTTP è¯·æ±‚
//
// æ–°ç‰¹æ€§:
// - è¿›åº¦ä¿å­˜: æ¯å¤„ç† 3 ä¸ªæ–‡ä»¶è‡ªåŠ¨ä¿å­˜è¿›åº¦åˆ° {output}.progress.json
// - è¿›åº¦æ¢å¤: ä¸­æ–­åé‡æ–°æ‰§è¡Œè‡ªåŠ¨ä»ä¸Šæ¬¡è¿›åº¦ç»§ç»­
// - ä¸´æ—¶ RAG: å®šæœŸä¿å­˜ä¸´æ—¶ RAG åˆ° {output}-tmp.rag
// - æ–­ç‚¹ç»­ä¼ : æ”¯æŒä¸­æ–­åä»ä¸´æ—¶ RAG æ¢å¤ï¼Œæ— éœ€é‡æ–°å¤„ç†å·²å®Œæˆçš„æ–‡ä»¶
//
// ä½¿ç”¨ç¤ºä¾‹:
// yak scripts/update-rag.yak --rag-file /path/to/old.rag --diff-zip diff-fs.zip --output /path/to/new.rag --embedding-host 127.0.0.1 --embedding-port 9099 --totp-secret my-secret --ai-api-key YOUR_KEY --ai-api-model MODEL_NAME --ai-api-domain api.example.com
//
// è¿›åº¦æ–‡ä»¶è¯´æ˜:
// - è¿›åº¦æ–‡ä»¶: {output}.progress.json (è®°å½•å·²å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨)
// - ä¸´æ—¶ RAG: {output}-tmp.rag (æ¯ 3 ä¸ªæ–‡ä»¶ä¿å­˜ä¸€æ¬¡)
// - å®Œæˆåè‡ªåŠ¨æ¸…ç†è¿›åº¦æ–‡ä»¶å’Œä¸´æ—¶ RAG
//
// åº”ç”¨åœºæ™¯: RAG å¢é‡æ›´æ–°ã€çŸ¥è¯†åº“åŒæ­¥ã€è‡ªåŠ¨åŒ–ç´¢å¼•æ›´æ–°ã€æ–­ç‚¹ç»­ä¼ 
// å…³é”®è¯: rag-update diff-update embedding-client incremental-update progress-resume
// æœç´¢æ ‡ç­¾: #rag #embedding #incremental-update #knowledge-base #progress-resume
// =============================================================================

__DESC__ = "Update RAG knowledge base with diff ZIP file"

yakit.AutoInitYakit()

// =============================================================================
// CLI å‚æ•°é…ç½®æ¨¡å— - å‘½ä»¤è¡Œæ¥å£å®šä¹‰
// åŠŸèƒ½: å®šä¹‰è„šæœ¬çš„å‘½ä»¤è¡Œå‚æ•°ï¼Œé…ç½® RAG æ–‡ä»¶ã€å·®å¼‚åŒ…ã€embedding æœåŠ¡ç­‰
// =============================================================================

// RAG æ–‡ä»¶è·¯å¾„ï¼ˆè¦å¯¼å…¥çš„åŸå§‹ RAG æ–‡ä»¶ï¼Œå¯é€‰ï¼‰
ragFilePath = cli.String(
    "rag-file",
    cli.setVerboseName("æ—§RAGè·¯å¾„"),
    cli.setDefault(""),
    cli.setHelp("Path to the RAG export file (.rag), if not specified, a new RAG will be created")
)

// å·®å¼‚ ZIP æ–‡ä»¶è·¯å¾„
diffZipPath = cli.String(
    "diff-zip",
    cli.setVerboseName("ZIPè·¯å¾„"),
    cli.setRequired(true),
    cli.setHelp("Path to the diff ZIP file")
)

// è¾“å‡º RAG æ–‡ä»¶è·¯å¾„
outputRagPath = cli.String(
    "output",
    cli.setVerboseName("è¾“å‡ºè·¯å¾„"),
    cli.setRequired(true),
    cli.setHelp("Output RAG export file path")
)

ragCollectionName = "yaklang-aikb"

// Embedding æœåŠ¡å™¨åœ°å€
embeddingHost = cli.String(
    "embedding-host",
    cli.setDefault("127.0.0.1"),
    cli.setHelp("Embedding server address")
)

// Embedding æœåŠ¡å™¨ç«¯å£
embeddingPort = cli.Int(
    "embedding-port",
    cli.setDefault(9099),
    cli.setHelp("Embedding server port")
)

// TOTP å¯†é’¥ï¼ˆå¯é€‰ï¼Œå¦‚æœ embedding æœåŠ¡éœ€è¦éªŒè¯ï¼‰
totpSecret = cli.String(
    "totp-secret",
    cli.setDefault(""),
    cli.setHelp("TOTP secret for embedding service authentication (optional)")
)

// è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
timeout = cli.Int(
    "timeout",
    cli.setDefault(30),
    cli.setHelp("HTTP request timeout in seconds")
)

// AI API Key
AIAPIKey = cli.String(
    "ai-api-key",
    cli.setRequired(true),
    cli.setHelp("AI API Key for AI service")
)

// AI API Model
AIAPIModel = cli.String(
    "ai-api-model",
    cli.setRequired(true),
    cli.setHelp("AI API Model for AI service")
)

// AI API Domain
AIAPIDomain = cli.String(
    "ai-api-domain",
    cli.setRequired(true),
    cli.setHelp("AI API Domain for AI service")
)

cli.check()

// =============================================================================
// å‚æ•°éªŒè¯æ¨¡å—
// =============================================================================

if diffZipPath == "" || outputRagPath == "" {
    die("Required parameters: --diff-zip, --output")
}

if ragFilePath != "" && !file.IsExisted(ragFilePath) {
    die(sprintf("RAG file does not exist: %s", ragFilePath))
}

if !file.IsExisted(diffZipPath) {
    die(sprintf("Diff ZIP file does not exist: %s", diffZipPath))
}

log.info("=== RAG Update Configuration ===")
if ragFilePath != "" {
    log.info("RAG File: %s (import existing)", ragFilePath)
} else {
    log.info("RAG File: Not specified (create new)")
}
log.info("Diff ZIP: %s", diffZipPath)
log.info("Output: %s", outputRagPath)
log.info("Collection: %s", ragCollectionName)
log.info("Embedding Server: %s:%d", embeddingHost, embeddingPort)
if totpSecret != "" {
    log.info("TOTP Auth: Enabled")
} else {
    log.info("TOTP Auth: Disabled")
}
log.info("AI API Model: %s", AIAPIModel)
log.info("AI API Domain: %s", AIAPIDomain)
log.info("AI API Key: [REDACTED]")

// =============================================================================
// Embedding å¤„ç†å‡½æ•°å®šä¹‰
// åŠŸèƒ½: å°è£… embedding è¯·æ±‚é€»è¾‘ï¼Œæ”¯æŒ TOTP éªŒè¯
// =============================================================================

// ç”¨äºæœ¬åœ°å¼€å‘ç¯å¢ƒ
dev_env_embeddingHandle = (text) => {
    if text == "" {
        log.error("Empty text for embedding")
        return nil
    }

    // ä¼˜åŒ–æ—¥å¿—è¾“å‡ºï¼šæ˜¾ç¤ºæ–‡æœ¬é¢„è§ˆ
    if len(text) <= 100 {
        log.info("Generating embedding for text (length: %d): %s", len(text), text)
    } else {
        preview = str.TrimSpace(text[:100])
        log.info("Generating embedding for text (length: %d), preview: %s...", len(text), preview)
    }

    data = {"input": text,"encoding_format":"float"}
    reqPacket = `POST /embeddings HTTP/1.1
Content-Type: application/json
Host: 127.0.0.1:11435

%v` % json.dumps(data)
    rsp,req,err = poc.HTTP(reqPacket, poc.timeout(30))
    if err {
        log.error("Failed to send embedding request: %v", err)
        return nil
    }

    body = poc.GetHTTPPacketBody(rsp)
    try {
        res = json.loads(body)[0]['embedding'][0]
        return res
    } catch err {
        println(body)
        log.error("Parse embedding data failed: %v" % err)
        return nil
    }

}

prod_env_embeddingHandle = func(text) {
    if text == "" {
        log.error("Empty text for embedding")
        return nil
    }

    // ä¼˜åŒ–æ—¥å¿—è¾“å‡ºï¼šæ˜¾ç¤ºæ–‡æœ¬é¢„è§ˆ
    if len(text) <= 100 {
        log.info("Generating embedding for text (length: %d): %s", len(text), text)
    } else {
        preview = str.TrimSpace(text[:100])
        log.info("Generating embedding for text (length: %d), preview: %s...", len(text), preview)
    }

    // å¦‚æœé…ç½®äº† TOTPï¼Œç”ŸæˆéªŒè¯ç 
    totpCode = ""
    if totpSecret != "" {
        totpCode = twofa.GetUTCCode(totpSecret)
        currentTime = time.Now().Unix()
        log.info("Generated TOTP code: %s (timestamp: %d)", totpCode, currentTime)
    }

    // æ„å»ºè¯·æ±‚ä½“
    requestBody = json.dumps({
        "input": text,
        "model": "embedding",
    })

    // æ„å»º HTTP è¯·æ±‚
    httpRequest = sprintf(`POST /embeddings HTTP/1.1
Host: %s
Content-Type: application/json`, embeddingHost)

    // å¦‚æœæœ‰ TOTPï¼Œæ·»åŠ éªŒè¯å¤´
    if totpCode != "" {
        httpRequest = sprintf(`%s
X-TOTP-Code: %s`, httpRequest, totpCode)
    }

    httpRequest = sprintf(`%s
Content-Length: %d

%s`, httpRequest, len(requestBody), requestBody)

    // å‘é€è¯·æ±‚
    try {
        rsp, _, err = poc.HTTP(
            httpRequest,
            poc.host(embeddingHost),
            poc.port(embeddingPort),
            poc.https(true),
            poc.timeout(timeout),
        )

        if err != nil {
            log.error("Failed to send embedding request: %v", err)
            return nil
        }

        // è·å–çŠ¶æ€ç 
        statusCode = poc.GetStatusCodeFromResponse(rsp)

        if statusCode != 200 {
            log.error("Embedding request failed with status code: %d", statusCode)
            _, body = poc.Split(rsp)
            log.error("Response body: %s", string(body))
            return nil
        }

        // è§£æå“åº”
        _, body = poc.Split(rsp)
        responseData = json.loads(body)

        if responseData["data"] == nil || len(responseData["data"]) == 0 {
            log.error("No embedding data in response")
            return nil
        }

        embeddingData = responseData["data"][0]
        embedding = embeddingData["embedding"]

        log.info("Embedding generated successfully (dimension: %d)", len(embedding))
        return embedding

    } catch embeddingErr {
        log.error("Failed to generate embedding: %v", embeddingErr)
        return nil
    }
}


prod_env_embeddingHandle_with_retry = func(text) {
    maxRetries = 5
    for i = 0; i < maxRetries; i++ {
        if i > 0 {
            log.warn("ğŸ”„ [RETRY %d/%d] Retrying embedding request...", i, maxRetries-1)
        }

        result = prod_env_embeddingHandle(text)
        if result != nil {
            if i > 0 {
                log.info("âœ“ Embedding succeeded after %d retries", i)
            }
            return result
        }

        if i < maxRetries - 1 {
            // ç­‰å¾…æ—¶é—´é€’å¢ï¼šç¬¬1æ¬¡é‡è¯•ç­‰1ç§’ï¼Œç¬¬2æ¬¡ç­‰2ç§’ï¼Œç¬¬3æ¬¡ç­‰3ç§’ï¼Œç¬¬4æ¬¡ç­‰4ç§’
            // è¿™æ ·å¯ä»¥è®© TOTP æœ‰æ›´å¤§æœºä¼šåˆ‡æ¢åˆ°æ–°çš„æ—¶é—´çª—å£
            waitSeconds = i + 1
            log.warn("â³ Embedding failed, waiting %d seconds before retry...", waitSeconds)
            time.Sleep(waitSeconds)
        }
    }

    log.error("âŒ Embedding failed after %d attempts, giving up", maxRetries)
    return nil
}

embeddingHandle = prod_env_embeddingHandle_with_retry

// =============================================================================
// RAG å¯¼å…¥/åˆ›å»ºæ¨¡å—
// åŠŸèƒ½: å¦‚æœæŒ‡å®šäº† RAG æ–‡ä»¶åˆ™å¯¼å…¥ï¼Œå¦åˆ™åˆ›å»ºæ–°çš„ RAG é›†åˆ
// =============================================================================

// ç§»é™¤ç°æœ‰é›†åˆ
rag.DeleteCollection(ragCollectionName)

if ragFilePath != "" {
    log.info("=== Step 1: Importing RAG file ===")

    try {
        err = rag.Import(ragFilePath, rag.importName(ragCollectionName))
        if err != nil {
            log.error("Failed to import RAG file: %v", err)
        }else{
            log.info("âœ“ RAG file imported successfully: %s", ragCollectionName)
        }
    } catch importErr {
        log.error("Failed to import RAG file: %v", importErr)
        die(sprintf("Failed to import RAG file: %v", importErr))
    }
} else {
    log.info("=== Step 1: Creating new RAG collection ===")
    log.info("No RAG file specified, will create a new collection: %s", ragCollectionName)
}

// =============================================================================
// åŠ è½½ RAG Collection
// åŠŸèƒ½: ä½¿ç”¨ embedding å¤„ç†å‡½æ•°åŠ è½½æˆ–åˆ›å»º RAG é›†åˆ
// =============================================================================

log.info("")
log.info("=== Step 2: Loading RAG collection ===")

ragSystem, err = rag.Get(ragCollectionName, rag.embeddingHandle(embeddingHandle))
if err != nil {
    log.error("Failed to load RAG collection: %v", err)
    die(sprintf("Failed to load RAG collection: %v", err))
}

if ragFilePath != "" {
    log.info("âœ“ RAG collection loaded successfully: %s", ragCollectionName)
} else {
    log.info("âœ“ New RAG collection created successfully: %s", ragCollectionName)
}

// è·å–æ—§ RAG çš„æ–‡æ¡£æ•°é‡
oldDocCount = 0
oldDocCount, err = ragSystem.CountDocuments()
if err != nil {
    log.error("Failed to get old document count: %v", err)
    oldDocCount = 0
} else {
    log.info("Old RAG document count: %d", oldDocCount)
}
// =============================================================================
// è¯»å–å·®å¼‚ ZIP æ–‡ä»¶
// åŠŸèƒ½: è§£æå·®å¼‚ ZIPï¼Œæå–æ‰€æœ‰æ–‡ä»¶å†…å®¹
// =============================================================================

log.info("")
log.info("=== Step 3: Reading diff ZIP file ===")

diffFiles = make(map[string]string)
fileCount = 0

err = zip.Recursive(diffZipPath, func(isDir, pathName, info) {
    if isDir {
        return
    }
    if str.HasPrefix(pathName, "__MACOSX/") {
        return
    }
    if info.Name() == ".DS_Store" {
        return
    }
    try {
        content = zip.ExtractFile(diffZipPath, pathName)~
        diffFiles[pathName] = string(content)
        fileCount++
        log.info("Extracted file: %s (size: %d bytes)", pathName, len(content))
    } catch extractErr {
        log.error("Failed to extract file %s: %v", pathName, extractErr)
    }
})

if err != nil {
    log.error("Failed to read diff ZIP file: %v", err)
    die(sprintf("Failed to read diff ZIP file: %v", err))
}

log.info("âœ“ Diff ZIP processed: %d files extracted", fileCount)

// æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶éœ€è¦å¤„ç†
if len(diffFiles) == 0 {
    log.info("âš ï¸  No files in diff ZIP, no updates needed")
    log.info("Exporting RAG file without changes...")

    // ç›´æ¥å¯¼å‡ºåŸ RAG
    try {
        err = rag.Export(ragCollectionName, outputRagPath)
        if err != nil {
            log.error("Failed to export RAG: %v", err)
            die(sprintf("Failed to export RAG: %v", err))
        }

        log.info("âœ“ RAG file exported: %s", outputRagPath)
        log.info("Script execution completed successfully (no changes)")
        os.Exit(0)

    } catch exportErr {
        log.error("Failed to export RAG: %v", exportErr)
        die(sprintf("Failed to export RAG: %v", exportErr))
    }
}

// =============================================================================
// è¿›åº¦ç®¡ç†æ¨¡å—
// åŠŸèƒ½: ä¿å­˜å’Œæ¢å¤å¤„ç†è¿›åº¦
// =============================================================================

// ç”Ÿæˆè¿›åº¦æ–‡ä»¶è·¯å¾„å’Œä¸´æ—¶ RAG è·¯å¾„
progressFilePath = str.Replace(outputRagPath, ".rag", ".progress.json", 1)
tmpRagPath = str.Replace(outputRagPath, ".rag", "-tmp.rag", 1)

log.info("")
log.info("=== Progress Management ===")
log.info("Progress file: %s", progressFilePath)
log.info("Temporary RAG: %s", tmpRagPath)

// å°è¯•æ¢å¤è¿›åº¦
processedFiles = []
shouldRestoreProgress = false

if file.IsExisted(progressFilePath) && file.IsExisted(tmpRagPath) {
    log.info("Found existing progress file and temporary RAG, attempting to restore...")
    
    try {
        progressContent = file.ReadFile(progressFilePath)~
        progressData = json.loads(string(progressContent))
        
        if progressData["processed_files"] != nil {
            processedFiles = progressData["processed_files"]
            shouldRestoreProgress = true
            log.info("âœ“ Progress restored: %d files already processed", len(processedFiles))
            
            // æ˜¾ç¤ºå·²å¤„ç†çš„æ–‡ä»¶
            for i, filePath := range processedFiles {
                log.info("  [%d] %s", i+1, filePath)
            }
        }
    } catch restoreErr {
        log.warn("Failed to restore progress: %v, starting from scratch", restoreErr)
        processedFiles = []
        shouldRestoreProgress = false
    }
}

// å¦‚æœéœ€è¦æ¢å¤è¿›åº¦,å¯¼å…¥ä¸´æ—¶ RAG è€Œä¸æ˜¯åŸå§‹ RAG
if shouldRestoreProgress {
    log.info("")
    log.info("=== Restoring from temporary RAG ===")
    
    // ç§»é™¤å½“å‰é›†åˆ
    rag.DeleteCollection(ragCollectionName)
    
    try {
        err = rag.Import(tmpRagPath, rag.importName(ragCollectionName))
        if err != nil {
            log.error("Failed to import temporary RAG: %v, starting from scratch", err)
            shouldRestoreProgress = false
            processedFiles = []
            
            // é‡æ–°å¯¼å…¥åŸå§‹ RAG
            if ragFilePath != "" {
                rag.DeleteCollection(ragCollectionName)
                err = rag.Import(ragFilePath, rag.importName(ragCollectionName))
                if err != nil {
                    die(sprintf("Failed to import original RAG: %v", err))
                }
            }
        } else {
            log.info("âœ“ Temporary RAG imported successfully")
        }
    } catch importErr {
        log.error("Failed to import temporary RAG: %v, starting from scratch", importErr)
        shouldRestoreProgress = false
        processedFiles = []
        
        // é‡æ–°å¯¼å…¥åŸå§‹ RAG
        if ragFilePath != "" {
            rag.DeleteCollection(ragCollectionName)
            err = rag.Import(ragFilePath, rag.importName(ragCollectionName))
            if err != nil {
                die(sprintf("Failed to import original RAG: %v", err))
            }
        }
    }
    
    // é‡æ–°åŠ è½½ RAG é›†åˆ
    ragSystem, err = rag.Get(ragCollectionName, rag.embeddingHandle(embeddingHandle))
    if err != nil {
        die(sprintf("Failed to reload RAG collection: %v", err))
    }
}

// =============================================================================
// æ·»åŠ æ–‡ä»¶åˆ° RAG
// åŠŸèƒ½: éå†å·®å¼‚æ–‡ä»¶ï¼Œæ·»åŠ åˆ° RAG é›†åˆä¸­ï¼Œæ”¯æŒè¿›åº¦ä¿å­˜å’Œæ¢å¤
// =============================================================================

log.info("")
log.info("=== Step 4: Adding files to RAG ===")

successCount = 0
failedCount = 0
failedFiles = []
totalFiles = len(diffFiles)
currentIndex = 0

// ä¿å­˜è¿›åº¦çš„å‡½æ•°
saveProgress = func() {
    progressData = {
        "processed_files": processedFiles,
        "success_count": successCount,
        "failed_count": failedCount,
        "failed_files": failedFiles,
        "last_update": time.Now().Format("2006-01-02 15:04:05"),
    }
    
    progressJson = json.dumps(progressData)
    err = file.Save(progressFilePath, progressJson)
    if err != nil {
        log.warn("Failed to save progress: %v", err)
    } else {
        log.info("Progress saved: %d/%d files processed", len(processedFiles), totalFiles)
    }
}

// ä¿å­˜ä¸´æ—¶ RAG çš„å‡½æ•°
saveTempRag = func() {
    try {
        err = rag.Export(ragCollectionName, tmpRagPath)
        if err != nil {
            log.warn("Failed to export temporary RAG: %v", err)
        } else {
            log.info("Temporary RAG saved: %s", tmpRagPath)
        }
    } catch exportErr {
        log.warn("Failed to export temporary RAG: %v", exportErr)
    }
}

// ç»Ÿè®¡éœ€è¦å¤„ç†çš„æ–‡ä»¶æ•°
filesToProcess = 0
for filePath, _ := range diffFiles {
    // æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
    alreadyProcessed = false
    for _, processed := range processedFiles {
        if processed == filePath {
            alreadyProcessed = true
            break
        }
    }
    if !alreadyProcessed {
        filesToProcess++
    }
}

log.info("Total files in diff: %d", totalFiles)
log.info("Already processed: %d", len(processedFiles))
log.info("Files to process: %d", filesToProcess)

for filePath, content := range diffFiles {
    currentIndex++
    
    // æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
    alreadyProcessed = false
    for _, processed := range processedFiles {
        if processed == filePath {
            alreadyProcessed = true
            break
        }
    }
    
    if alreadyProcessed {
        log.info("[%d/%d] Skipping already processed file: %s", currentIndex, totalFiles, filePath)
        successCount++
        continue
    }
    
    if content == "" {
        log.warn("[%d/%d] Skipping empty file: %s", currentIndex, totalFiles, filePath)
        continue
    }

    log.info("[%d/%d] Processing file: %s (size: %d bytes)", currentIndex, totalFiles, filePath, len(content))

    try {
        if str.HasSuffix(filePath, ".yak") {
            tempFileName,err := file.TempFileName("temp-*.yak")
            if err {
                die("create temp file failed: %v" % err)
            }
            file.Save(tempFileName, content)~
            opts = [
                rag.embeddingHandle(prod_env_embeddingHandle),
                rag.aiServiceType("openai",ai.apiKey(AIAPIKey),ai.model(AIAPIModel),ai.domain(AIAPIDomain)),
                rag.extraPrompt("This code sample is written in Yaklang programming language. Yaklang is a domain-specific language designed for cybersecurity and penetration testing. When generating questions and indexing this code, focus on Yaklang-specific syntax, built-in functions, security testing patterns, and practical usage scenarios in the context of security research and vulnerability assessment."),
            ]
            err = rag.BuildIndexKnowledgeFromFile(ragCollectionName, tempFileName, opts...)
            if err {
                die("add yak file %v to rag error: %v" % err)
            }
        } else {
            err = ragSystem.Add(filePath, content)
            if err {
                die("add text file %v to rag error: %v" % err)
            }
        }
        successCount++
        processedFiles = append(processedFiles, filePath)
        log.info("âœ“ [%d/%d] Added: %s", currentIndex, totalFiles, filePath)
        
        // æ¯å¤„ç† 3 ä¸ªæ–‡ä»¶,ä¿å­˜ä¸€æ¬¡è¿›åº¦å’Œä¸´æ—¶ RAG
        if len(processedFiles) % 3 == 0 {
            log.info("")
            log.info("=== Checkpoint: Saving progress and temporary RAG ===")
            saveProgress()
            saveTempRag()
            log.info("")
        }
        
    } catch addErr {
        log.error("âœ— [%d/%d] Failed to add file %s: %v", currentIndex, totalFiles, filePath, addErr)
        failedCount++
        failedFiles = append(failedFiles, filePath)
        processedFiles = append(processedFiles, filePath)
        
        // å¤±è´¥åä¹Ÿä¿å­˜è¿›åº¦
        saveProgress()
    }
}

// æœ€åä¿å­˜ä¸€æ¬¡è¿›åº¦å’Œä¸´æ—¶ RAG
log.info("")
log.info("=== Final checkpoint: Saving progress and temporary RAG ===")
saveProgress()
saveTempRag()

log.info("")
log.info("=== Add Results ===")
log.info("Success: %d files", successCount)
log.info("Failed: %d files", failedCount)

if failedCount > 0 {
    log.warn("Failed files:")
    for i, filePath := range failedFiles {
        log.warn("  %d. %s", i+1, filePath)
    }
}

// è·å–æ–° RAG çš„æ–‡æ¡£æ•°é‡
newDocCount = 0
newDocCount, err = ragSystem.CountDocuments()
if err != nil {
    log.error("Failed to get new document count: %v", err)
    newDocCount = 0
} else {
    log.info("New RAG document count: %d", newDocCount)
    log.info("Document count increased: %d", newDocCount - oldDocCount)
}

// =============================================================================
// å¯¼å‡º RAG æ–‡ä»¶
// åŠŸèƒ½: å°†æ›´æ–°åçš„ RAG é›†åˆå¯¼å‡ºåˆ°æ–‡ä»¶
// =============================================================================

log.info("")
log.info("=== Step 5: Exporting RAG file ===")
try {
    err = rag.Export(ragCollectionName, outputRagPath)
    if err != nil {
        log.error("Failed to export RAG: %v", err)
        die(sprintf("Failed to export RAG to %s", outputRagPath))
    }

    // éªŒè¯å¯¼å‡ºçš„æ–‡ä»¶
    if !file.IsExisted(outputRagPath) {
        log.error("Export succeeded but file does not exist: %s", outputRagPath)
        die("Failed to verify exported RAG file")
    }

    // è·å–æ–‡ä»¶å¤§å°
    fileInfo = file.Stat(outputRagPath)~
    fileSize = fileInfo.Size()

    log.info("âœ“ RAG file exported successfully: %s", outputRagPath)
    log.info("  File size: %d bytes (%.2f MB)", fileSize, float64(fileSize)/1024/1024)

} catch exportErr {
    log.error("Failed to export RAG: %v", exportErr)
    die(sprintf("Failed to export RAG: %v", exportErr))
}

// =============================================================================
// æ¸…ç†ä¸´æ—¶æ–‡ä»¶
// åŠŸèƒ½: åˆ é™¤è¿›åº¦æ–‡ä»¶å’Œä¸´æ—¶ RAG æ–‡ä»¶
// =============================================================================

log.info("")
log.info("=== Step 6: Cleaning up temporary files ===")

// åˆ é™¤è¿›åº¦æ–‡ä»¶
if file.IsExisted(progressFilePath) {
    err = file.Remove(progressFilePath)
    if err != nil {
        log.warn("Failed to remove progress file: %v", err)
    } else {
        log.info("âœ“ Progress file removed: %s", progressFilePath)
    }
}

// åˆ é™¤ä¸´æ—¶ RAG æ–‡ä»¶
if file.IsExisted(tmpRagPath) {
    err = file.Remove(tmpRagPath)
    if err != nil {
        log.warn("Failed to remove temporary RAG: %v", err)
    } else {
        log.info("âœ“ Temporary RAG removed: %s", tmpRagPath)
    }
}

// =============================================================================
// ç”Ÿæˆæ›´æ–°æŠ¥å‘Š
// åŠŸèƒ½: ç”Ÿæˆ Markdown æ ¼å¼çš„æ›´æ–°æŠ¥å‘Š
// =============================================================================

log.info("")
log.info("=== Step 7: Generating update report ===")

reportPath = str.Replace(outputRagPath, ".rag", ".update-report.md", 1)

report = sprintf("# RAG æ›´æ–°æŠ¥å‘Š\n\n")
report += sprintf("**æ›´æ–°æ—¶é—´**: %s\n\n", time.Now().Format("2006-01-02 15:04:05"))
if ragFilePath != "" {
    report += sprintf("**åŸå§‹ RAG**: %s (å¯¼å…¥)\n", ragFilePath)
} else {
    report += sprintf("**åŸå§‹ RAG**: æ— ï¼ˆæ–°å»ºï¼‰\n")
}
report += sprintf("**å·®å¼‚åŒ…**: %s\n", diffZipPath)
report += sprintf("**è¾“å‡º RAG**: %s\n", outputRagPath)
report += sprintf("**é›†åˆåç§°**: %s\n\n", ragCollectionName)

report += "## æ–‡æ¡£æ•°é‡ç»Ÿè®¡\n\n"
report += sprintf("- æ—§ RAG æ–‡æ¡£æ•°é‡: %d\n", oldDocCount)
report += sprintf("- æ–° RAG æ–‡æ¡£æ•°é‡: %d\n", newDocCount)
report += sprintf("- æ–‡æ¡£å¢é‡: %d\n\n", newDocCount - oldDocCount)

report += "## å¤„ç†ç»Ÿè®¡\n\n"
report += sprintf("- å·®å¼‚æ–‡ä»¶æ€»æ•°: %d\n", len(diffFiles))
report += sprintf("- æˆåŠŸæ·»åŠ : %d\n", successCount)
report += sprintf("- æ·»åŠ å¤±è´¥: %d\n\n", failedCount)

if successCount > 0 {
    report += "## æˆåŠŸæ·»åŠ çš„æ–‡ä»¶\n\n"
    idx = 1
    for filePath, _ := range diffFiles {
        // æ£€æŸ¥æ˜¯å¦åœ¨å¤±è´¥åˆ—è¡¨ä¸­
        isFailed := false
        for _, failedFile := range failedFiles {
            if failedFile == filePath {
                isFailed = true
                break
            }
        }

        if !isFailed {
            report += sprintf("%d. %s\n", idx, filePath)
            idx++
        }
    }
    report += "\n"
}

if failedCount > 0 {
    report += "## æ·»åŠ å¤±è´¥çš„æ–‡ä»¶\n\n"
    for i, filePath := range failedFiles {
        report += sprintf("%d. %s\n", i+1, filePath)
    }
    report += "\n"
}

report += "## Embedding é…ç½®\n\n"
report += sprintf("- æœåŠ¡å™¨: %s:%d\n", embeddingHost, embeddingPort)
if totpSecret != "" {
    report += "- TOTP è®¤è¯: å¯ç”¨\n"
} else {
    report += "- TOTP è®¤è¯: ç¦ç”¨\n"
}
report += sprintf("- è¶…æ—¶æ—¶é—´: %d ç§’\n\n", timeout)

report += "## è¾“å‡ºæ–‡ä»¶ä¿¡æ¯\n\n"
report += sprintf("- æ–‡ä»¶è·¯å¾„: %s\n", outputRagPath)
if file.IsExisted(outputRagPath) {
    fileInfo = file.Stat(outputRagPath)~
    fileSize = fileInfo.Size()
    report += sprintf("- æ–‡ä»¶å¤§å°: %d bytes (%.2f MB)\n", fileSize, float64(fileSize)/1024/1024)
}

// ä¿å­˜æŠ¥å‘Š
err = file.Save(reportPath, report)
if err != nil {
    log.warn("Failed to write report: %v", err)
} else {
    log.info("âœ“ Update report generated: %s", reportPath)
}

// æ‰“å°æŠ¥å‘Šåˆ°æ§åˆ¶å°
println("")
println(report)

// =============================================================================
// ç”Ÿæˆ JSON æŠ¥å‘Š
// åŠŸèƒ½: ç”Ÿæˆæœºå™¨å¯è¯»çš„ JSON æ ¼å¼æ›´æ–°æŠ¥å‘Š
// =============================================================================

log.info("")
log.info("=== Step 8: Generating JSON report ===")

jsonReportPath = str.Replace(outputRagPath, ".rag", ".update-report.json", 1)

// è·å–è¾“å‡ºæ–‡ä»¶ä¿¡æ¯
outputFileSize = 0
if file.IsExisted(outputRagPath) {
    fileInfo = file.Stat(outputRagPath)~
    outputFileSize = fileInfo.Size()
}

// æ”¶é›†æˆåŠŸå’Œå¤±è´¥çš„æ–‡ä»¶åˆ—è¡¨
successFiles = []
for filePath, _ := range diffFiles {
    isFailed := false
    for _, failedFile := range failedFiles {
        if failedFile == filePath {
            isFailed = true
            break
        }
    }
    if !isFailed {
        successFiles = append(successFiles, filePath)
    }
}

// æ„å»º JSON æ•°æ®ç»“æ„
jsonData = {
    "update_time": time.Now().Format("2006-01-02 15:04:05"),
    "update_timestamp": time.Now().Unix(),
    "status": failedCount == 0 ? "success" : "partial_failure",
    "config": {
        "rag_file": ragFilePath,
        "diff_zip": diffZipPath,
        "output_rag": outputRagPath,
        "collection_name": ragCollectionName,
        "embedding_host": "***",
        "embedding_port": "***",
        "totp_enabled": totpSecret != "",
        "timeout": timeout,
        "ai_api_model": "***",
        "ai_api_domain": "***",
    },
    "statistics": {
        "old_document_count": oldDocCount,
        "new_document_count": newDocCount,
        "document_increased": newDocCount - oldDocCount,
        "diff_files_total": len(diffFiles),
        "success_count": successCount,
        "failed_count": failedCount,
    },
    "files": {
        "success": successFiles,
        "failed": failedFiles,
    },
    "output": {
        "rag_file": outputRagPath,
        "rag_file_size_bytes": outputFileSize,
        "rag_file_size_mb": sprintf("%.2f", float64(outputFileSize)/1024/1024),
        "markdown_report": reportPath,
        "json_report": jsonReportPath,
    },
}

// è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
jsonString = json.dumps(jsonData)

// ä¿å­˜ JSON æŠ¥å‘Š
err = file.Save(jsonReportPath, jsonString)
if err != nil {
    log.warn("Failed to write JSON report: %v", err)
} else {
    log.info("âœ“ JSON report generated: %s", jsonReportPath)
}

// =============================================================================
// æ€»ç»“è¾“å‡º
// =============================================================================

log.info("")
log.info("=== Update Summary ===")
log.info("âœ“ RAG update completed successfully")
log.info("  - Old document count: %d", oldDocCount)
log.info("  - New document count: %d", newDocCount)
log.info("  - Document increased: %d", newDocCount - oldDocCount)
log.info("  - Processed: %d files", len(diffFiles))
log.info("  - Success: %d files", successCount)
log.info("  - Failed: %d files", failedCount)
log.info("  - Output: %s", outputRagPath)
log.info("  - Report: %s", reportPath)
log.info("  - JSON Report: %s", jsonReportPath)


if failedCount > 0 {
    log.warn("âš ï¸  Some files failed to add, please check the report")
    os.Exit(1)
} else {
    log.info("âœ“ All files processed successfully")
    os.Exit(0)
}