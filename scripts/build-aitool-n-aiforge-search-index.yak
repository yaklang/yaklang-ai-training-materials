#!/usr/bin/env yak

// =============================================================================
// AI èƒ½åŠ›æœç´¢ç´¢å¼•æ„å»ºå·¥å…· - Build AI Capabilities (Tools + Forges) Search Index
// åŠŸèƒ½: ä»æ•°æ®åº“ä¸­è·å–æ‰€æœ‰ AI Tools å’Œ AI Forgesï¼Œæ„å»ºç»Ÿä¸€çš„æœç´¢ç´¢å¼•
// ç”¨é€”: ä¸ºæ‰€æœ‰ AI èƒ½åŠ›æ„å»ºå¯æœç´¢çš„é—®é¢˜ç´¢å¼•ï¼Œè®©ç”¨æˆ·èƒ½é€šè¿‡è‡ªç„¶è¯­è¨€æŸ¥è¯¢æ‰¾åˆ°åˆé€‚çš„å·¥å…·/Forge
//
// æ ¸å¿ƒè®¾è®¡:
// - åŒæ—¶å¤„ç† db.YieldAllAITools() å’Œ db.YieldAllAIForges()
// - çŸ¥è¯†æ¡ç›®ï¼ˆå·¥å…·/Forgeæè¿°ï¼‰-> å¤šä¸ªé—®é¢˜ç´¢å¼•
// - é—®é¢˜ç´¢å¼•ç”¨äºè¯­ä¹‰æœç´¢
// - æœç´¢ç»“æœé€šè¿‡ entry_id å…³è”åˆ°çŸ¥è¯†æ¡ç›®
//
// å¢é‡æ›´æ–°æœºåˆ¶:
// - å¦‚æœæŒ‡å®šçš„ RAG æ–‡ä»¶å·²å­˜åœ¨ï¼Œè‡ªåŠ¨åŠ è½½å¹¶è¿›è¡Œå¢é‡æ›´æ–°
// - ä½¿ç”¨æ¨¡ç³Šæœç´¢æ£€æŸ¥æ¡ç›®æ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…é‡å¤æ·»åŠ 
// - èŠ‚çœ AI è°ƒç”¨æˆæœ¬å’Œæ„å»ºæ—¶é—´
//
// ä½¿ç”¨ç¤ºä¾‹:
// go run common/yak/cmd/yak.go scripts/build-aitool-n-aiforge-search-index.yak --output /tmp/ai-capabilities-{version}.rag
//
// åº”ç”¨åœºæ™¯: AI èƒ½åŠ›ç´¢å¼•æ„å»ºã€å·¥å…·/Forgeæœç´¢ç³»ç»Ÿã€è‡ªåŠ¨åŒ–ç´¢å¼•æ›´æ–°
// =============================================================================

__DESC__ = "Build search index for AI Tools and AI Forges using BuildSearchIndexKnowledge"

yakit.AutoInitYakit()

// =============================================================================
// CLI å‚æ•°é…ç½®æ¨¡å—
// æ‰€æœ‰å‚æ•°å‡ä¸ºå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨å†…ç½®æœåŠ¡ï¼Œæ— éœ€é¢å¤–é…ç½®
// =============================================================================

// è¾“å‡º RAG æ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
outputRagPath = cli.String(
    "output",
    cli.setVerboseName("è¾“å‡ºè·¯å¾„"),
    cli.setDefault("/tmp/ai-capabilities-{version}.rag"),
    cli.setHelp("Output RAG export file path. Use {version} placeholder for Yak version. Example: /tmp/ai-capabilities-{version}.rag")
)

// å¹¶å‘æ•°
maxConcurrency = cli.Int(
    "concurrency",
    cli.setDefault(5),
    cli.setHelp("Maximum number of concurrent processing tasks")
)

// å¼ºåˆ¶é‡å»ºï¼ˆå¿½ç•¥å·²æœ‰çš„ RAG æ–‡ä»¶ï¼‰
forceRebuild = cli.Bool(
    "force",
    cli.setVerboseName("å¼ºåˆ¶é‡å»º"),
    cli.setDefault(false),
    cli.setHelp("Force rebuild index, ignore existing RAG file")
)

cli.check()

// =============================================================================
// ç‰ˆæœ¬æ£€æµ‹å’Œè¾“å‡ºè·¯å¾„é…ç½®
// =============================================================================

// ä½¿ç”¨å†…ç½®çš„ YAK_VERSION å˜é‡è·å–ç‰ˆæœ¬
yakVersion = YAK_VERSION
if yakVersion == "" || yakVersion == undefined {
    yakVersion = "dev"
}

log.info("=== AI Capabilities Search Index Builder ===")
log.info("ğŸ·ï¸  Yak Version: %s", yakVersion)

// å¤„ç†è¾“å‡ºè·¯å¾„
// 1. å¦‚æœåŒ…å« {version}ï¼Œæ›¿æ¢ä¸ºå®é™…ç‰ˆæœ¬
// 2. å¦‚æœä¸ä»¥ .rag ç»“å°¾ï¼Œè¿½åŠ  .rag
finalOutputPath = outputRagPath

// æ›¿æ¢ {version} å ä½ç¬¦
if str.Contains(finalOutputPath, "{version}") {
    finalOutputPath = str.Replace(finalOutputPath, "{version}", yakVersion, -1)
}

// ç¡®ä¿ä»¥ .rag ç»“å°¾
if !str.HasSuffix(finalOutputPath, ".rag") {
    finalOutputPath = finalOutputPath + ".rag"
}

log.info("ğŸ“ Output RAG: %s", finalOutputPath)
log.info("âš¡ Concurrency: %d", maxConcurrency)
log.info("ğŸ”„ Force Rebuild: %v", forceRebuild)

// =============================================================================
// RAG ç³»ç»Ÿåˆå§‹åŒ–ï¼ˆæ”¯æŒå¢é‡æ›´æ–°ï¼‰
// =============================================================================

ragCollectionName = "yaklang-ai-capabilities"

// æ£€æŸ¥ RAG æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå†³å®šæ˜¯å¢é‡æ›´æ–°è¿˜æ˜¯å…¨æ–°æ„å»º
existingRagFile = file.IsExisted(finalOutputPath)
incrementalMode = existingRagFile && !forceRebuild

if incrementalMode {
    log.info("")
    log.info("=== Incremental Update Mode ===")
    log.info("ğŸ“‚ Found existing RAG file: %s", finalOutputPath)
    log.info("ğŸ”„ Will perform incremental update (use --force to rebuild)")
    
    // å…ˆåˆ é™¤å¯èƒ½å­˜åœ¨çš„åŒåé›†åˆï¼Œé¿å…å†²çª
    rag.DeleteCollection(ragCollectionName)
    
    // å¯¼å…¥ç°æœ‰çš„ RAG æ–‡ä»¶
    try {
        err = rag.Import(finalOutputPath, rag.importName(ragCollectionName))
        if err != nil {
            log.warn("âš ï¸  Failed to import existing RAG file: %v", err)
            log.info("ğŸ”„ Falling back to full rebuild mode")
            incrementalMode = false
            rag.DeleteCollection(ragCollectionName)
        } else {
            log.info("âœ“ Successfully imported existing RAG file")
        }
    } catch importErr {
        log.warn("âš ï¸  Failed to import existing RAG file: %v", importErr)
        log.info("ğŸ”„ Falling back to full rebuild mode")
        incrementalMode = false
        rag.DeleteCollection(ragCollectionName)
    }
} else {
    log.info("")
    log.info("=== Full Build Mode ===")
    if existingRagFile && forceRebuild {
        log.info("ğŸ”„ Force rebuild requested, ignoring existing file")
    } else {
        log.info("ğŸ“ No existing RAG file found, creating new index")
    }
    // ç§»é™¤ç°æœ‰é›†åˆ
    rag.DeleteCollection(ragCollectionName)
}

log.info("")
log.info("=== Initializing RAG System ===")

ragSystem, err = rag.Get(ragCollectionName)
if err != nil {
    log.error("âŒ Failed to initialize RAG system: %v", err)
    die(sprintf("Failed to initialize RAG system: %v", err))
}

log.info("âœ“ RAG system initialized successfully")
log.info("   ğŸ“š Collection name: %s", ragCollectionName)

// è·å–ç°æœ‰æ–‡æ¡£æ•°é‡
existingDocCount = 0
try {
    existingDocCount, _ = ragSystem.CountDocuments()
    log.info("   ğŸ“Š Existing documents: %d", existingDocCount)
} catch countErr {
    log.debug("Failed to count existing documents: %v", countErr)
}

// =============================================================================
// é¢„åŠ è½½å·²å­˜åœ¨çš„çŸ¥è¯†æ¡ç›®ï¼ˆç”¨äºå¿«é€Ÿå»é‡æ£€æŸ¥ï¼‰
// =============================================================================

// ä¸€æ¬¡æ€§é¢„åŠ è½½æ‰€æœ‰å·²å­˜åœ¨çš„çŸ¥è¯†æ¡ç›®çš„ KnowledgeTitle
// å­˜å‚¨åœ¨å†…å­˜ map ä¸­ï¼Œç”¨äº O(1) å¿«é€ŸæŸ¥æ‰¾
existingKnowledgeTitles = {}  // map[string]bool

// é¢„åŠ è½½å‡½æ•° - ä¸€æ¬¡æ€§è·å–æ‰€æœ‰å·²å­˜åœ¨çš„çŸ¥è¯†æ¡ç›®ï¼ˆä½¿ç”¨ DISTINCT é«˜æ•ˆæŸ¥è¯¢ï¼‰
preloadExistingKnowledge = func() {
    if !incrementalMode {
        return
    }
    
    log.info("ğŸ“‹ Preloading existing knowledge titles (using DISTINCT query)...")
    preloadStart = time.Now()
    
    try {
        // ä½¿ç”¨ DBQueryUniqueKnowledgeTitles ç›´æ¥è·å–å”¯ä¸€æ ‡é¢˜ï¼ˆSQL DISTINCTï¼Œé«˜æ•ˆï¼‰
        titles, err = rag.DBQueryUniqueKnowledgeTitles(rag.dbQueryCollection(ragCollectionName), rag.dbQueryLimit(50000))
        if err != nil {
            log.warn("Failed to preload knowledge titles: %v", err)
            return
        }
        
        // å­˜å‚¨åˆ° map ä¸­
        for _, title := range titles {
            if title != "" {
                existingKnowledgeTitles[title] = true
            }
        }
        
        preloadElapsed = time.Since(preloadStart)
        log.info("âœ“ Preloaded %d unique knowledge titles in %v", len(existingKnowledgeTitles), preloadElapsed)
    } catch preloadErr {
        log.warn("Failed to preload knowledge titles: %v", preloadErr)
    }
}

// å¿«é€Ÿæ£€æŸ¥æ¡ç›®æ˜¯å¦å·²å­˜åœ¨ï¼ˆä½¿ç”¨é¢„åŠ è½½çš„ mapï¼ŒO(1) æŸ¥æ‰¾ï¼‰
checkItemExists = func(itemName, itemType) {
    if !incrementalMode {
        return false
    }
    
    // ç›´æ¥ä»å†…å­˜ map æŸ¥æ‰¾ï¼ŒO(1) å¤æ‚åº¦ï¼Œçº³ç§’çº§
    if itemName in existingKnowledgeTitles {
        return true
    }
    
    return false
}

// =============================================================================
// è¿‡æ»¤å‡½æ•°ï¼šè·³è¿‡ mock å’Œ æµ‹è¯•å·¥å…·/Forge
// =============================================================================

shouldSkipItem = func(name) {
    lowerName = str.ToLower(name)
    // è¿‡æ»¤ mock_ å¼€å¤´çš„å·¥å…·ï¼ˆæµ‹è¯•ç”¨ï¼‰
    if str.HasPrefix(lowerName, "mock_") {
        return true
    }
    // è¿‡æ»¤åŒ…å« mock çš„å·¥å…·
    if str.Contains(lowerName, "mock") {
        return true
    }
    // è¿‡æ»¤ sleep å·¥å…·ï¼ˆæµ‹è¯•ç”¨ï¼‰
    if lowerName == "sleep" || str.HasPrefix(lowerName, "sleep_") {
        return true
    }
    // è¿‡æ»¤ test_ å¼€å¤´çš„å·¥å…·ï¼ˆæµ‹è¯•ç”¨ï¼‰
    if str.HasPrefix(lowerName, "test_") {
        return true
    }
    // è¿‡æ»¤åŒ…å« test çš„å·¥å…·
    if str.Contains(lowerName, "test") {
        return true
    }
    return false
}

// =============================================================================
// è·å– AI å·¥å…·åˆ—è¡¨
// =============================================================================

log.info("")
log.info("=== Loading AI Tools and Forges ===")

// é¢„åŠ è½½å·²å­˜åœ¨çš„çŸ¥è¯†æ¡ç›®ï¼ˆå¢é‡æ¨¡å¼ä¸‹ï¼‰
if incrementalMode {
    preloadExistingKnowledge()
}

allItems = []  // ç»Ÿä¸€å­˜å‚¨æ‰€æœ‰å¾…å¤„ç†é¡¹
toolCount = 0
toolSkippedCount = 0
toolExistsCount = 0

log.info("")
log.info("ğŸ“‹ Collecting AI Tools...")

for ins in db.YieldAllAITools() {
    toolName = ins.Name || ""
    // è¿‡æ»¤æ‰ mock å’Œ sleep ç›¸å…³çš„å·¥å…·
    if shouldSkipItem(toolName) {
        toolSkippedCount++
        log.debug("   â­ï¸  Skipping mock/test tool: %s", toolName)
        continue
    }
    
    // æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆå¢é‡æ›´æ–°æ¨¡å¼ï¼‰
    if checkItemExists(toolName, "tool") {
        toolExistsCount++
        log.debug("   âœ“ Tool already indexed: %s", toolName)
        continue
    }
    
    // å°è£…ä¸ºç»Ÿä¸€æ ¼å¼
    item = {
        "type": "tool",
        "name": toolName,
        "verbose_name": ins.VerboseName || toolName,
        "description": ins.Description || "",
        "keywords": ins.Keywords || [],
        "content": ins.Content || "",
    }
    allItems = append(allItems, item)
    toolCount++
}

log.info("âœ“ Found %d new AI tools to process", toolCount)
log.info("   â­ï¸  Skipped mock/test: %d", toolSkippedCount)
if incrementalMode {
    log.info("   âœ“ Already indexed: %d", toolExistsCount)
}

// =============================================================================
// è·å– AI Forge åˆ—è¡¨
// =============================================================================

log.info("")
log.info("=== Loading AI Forges ===")

forgeCount = 0
forgeSkippedCount = 0
forgeExistsCount = 0

for ins in db.YieldAllAIForges() {
    forgeName = ins.ForgeName || ""
    // è¿‡æ»¤æ‰ mock å’Œ sleep ç›¸å…³çš„ Forge
    if shouldSkipItem(forgeName) {
        forgeSkippedCount++
        log.debug("   â­ï¸  Skipping mock/test forge: %s", forgeName)
        continue
    }
    
    // æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆå¢é‡æ›´æ–°æ¨¡å¼ï¼‰
    if checkItemExists(forgeName, "forge") {
        forgeExistsCount++
        log.debug("   âœ“ Forge already indexed: %s", forgeName)
        continue
    }
    
    // å°è£…ä¸ºç»Ÿä¸€æ ¼å¼
    item = {
        "type": "forge",
        "name": forgeName,
        "verbose_name": ins.ForgeVerboseName || forgeName,
        "description": ins.Description || "",
        "keywords": [],  // Forge å¯èƒ½æ²¡æœ‰ keywords å­—æ®µ
        "content": ins.ForgeContent || "",
    }
    allItems = append(allItems, item)
    forgeCount++
}

log.info("âœ“ Found %d new AI forges to process", forgeCount)
log.info("   â­ï¸  Skipped mock/test: %d", forgeSkippedCount)
if incrementalMode {
    log.info("   âœ“ Already indexed: %d", forgeExistsCount)
}

totalCount = len(allItems)
log.info("")
log.info("ğŸ“Š Total new items to process: %d (Tools: %d, Forges: %d)", totalCount, toolCount, forgeCount)

if totalCount == 0 {
    if incrementalMode {
        log.info("âœ“ All items are already indexed, nothing to update")
        // ç›´æ¥å¯¼å‡ºç°æœ‰æ•°æ®
        try {
            err = rag.Export(ragCollectionName, finalOutputPath)
            if err != nil {
                log.error("âŒ Failed to export RAG file: %v", err)
                die(sprintf("Failed to export RAG file: %v", err))
            }
            log.info("âœ“ RAG file exported (no changes): %s", finalOutputPath)
        } catch exportErr {
            log.error("âŒ Failed to export RAG file: %v", exportErr)
            die(sprintf("Failed to export RAG file: %v", exportErr))
        }
        os.Exit(0)
    } else {
        log.warn("âš ï¸  No AI tools or forges found in database")
        die("No items to process")
    }
}

// =============================================================================
// å¹¶å‘å¤„ç†è®¾ç½®
// =============================================================================

wg = sync.NewSizedWaitGroup(maxConcurrency)
resultsChan = make(chan map[string]any, totalCount)

// ç»Ÿè®¡å˜é‡
totalQuestions = 0
questionsMutex = sync.NewMutex()

// å¤„ç†å•ä¸ªé¡¹ç›®çš„å‡½æ•°
processItem = func(itemIndex, totalItems, itemInfo) {
    defer wg.Done()

    itemType = itemInfo["type"]
    itemName = itemInfo["name"]
    verboseName = itemInfo["verbose_name"]
    description = itemInfo["description"]
    keywords = itemInfo["keywords"]
    content = itemInfo["content"]

    typeLabel = "ğŸ”§ Tool"
    if itemType == "forge" {
        typeLabel = "ğŸ”¨ Forge"
    }

    result = {
        "type": itemType,
        "name": itemName,
        "verbose_name": verboseName,
        "description": description,
        "success": false,
        "error": nil,
        "questions_generated": 0,
    }

    try {
        log.info("")
        log.info("========================================")
        log.info("%s [%d/%d] Processing: %s", typeLabel, itemIndex, totalItems, itemName)
        log.info("   ğŸ†” ID: %s", itemName)
        if verboseName != itemName {
            log.info("   ğŸ“ Verbose Name: %s", verboseName)
        }
        if description != "" {
            descPreview = description
            if len(descPreview) > 100 {
                descPreview = descPreview[:100] + "..."
            }
            log.info("   ğŸ“‹ Description: %s", descPreview)
        }
        if len(keywords) > 0 {
            log.info("   ğŸ·ï¸  Keywords: %s", str.Join(keywords, ", "))
        }
        log.info("----------------------------------------")

        // æ„å»ºæè¿°æ–‡æœ¬ï¼ˆä½œä¸ºçŸ¥è¯†æ¡ç›®å†…å®¹ï¼‰
        keywordsStr = ""
        if len(keywords) > 0 {
            keywordsStr = str.Join(keywords, ", ")
        }

        itemTypeCN = "Yaklang AI å·¥å…·"
        if itemType == "forge" {
            itemTypeCN = "Yaklang AI Forge"
        }

        itemDescription = sprintf(`åç§°: %s
æ˜¾ç¤ºåç§°: %s
ç±»å‹: %s
åŠŸèƒ½æè¿°: %s
å…³é”®è¯: %s

è¿™æ˜¯ä¸€ä¸ª %sï¼Œå¯ä»¥ç”¨äº:
- %s

ä½¿ç”¨åœºæ™¯:
- å®‰å…¨æµ‹è¯•å’Œæ¼æ´è¯„ä¼°
- è‡ªåŠ¨åŒ–ä»»åŠ¡æ‰§è¡Œ
- é›†æˆåˆ° Yaklang å®‰å…¨æµ‹è¯•æ¡†æ¶`,
            itemName,
            verboseName,
            itemTypeCN,
            description,
            keywordsStr,
            itemTypeCN,
            description || "å®‰å…¨æµ‹è¯•ä»»åŠ¡")

        log.info("   ğŸ”¨ Step 1: Building search index...")
        log.info("   ğŸ“ Description length: %d bytes", len(itemDescription))

        // AI èƒ½åŠ›åœºæ™¯çš„ extraPrompt - å¼ºåŒ–å·¥å…·/Forgeæ„å›¾è¯†åˆ«
        aiCapabilityExtraPrompt = sprintf(`
ã€AI èƒ½åŠ›æœç´¢åœºæ™¯å¼ºåŒ–è¯´æ˜ã€‘
è¿™æ˜¯ä¸€ä¸ª %s çš„æè¿°ä¿¡æ¯ï¼Œç”¨äºå®‰å…¨æµ‹è¯•ã€è‡ªåŠ¨åŒ–ä»»åŠ¡ã€ä¿¡æ¯æ”¶é›†ç­‰åœºæ™¯ã€‚

ç”Ÿæˆé—®é¢˜æ—¶ï¼Œè¯·ç‰¹åˆ«å…³æ³¨ï¼š
1. ç”¨æˆ·å¯èƒ½ç”¨ä»€ä¹ˆè‡ªç„¶è¯­è¨€æè¿°æ¥æ‰¾åˆ°è¿™ä¸ª%sï¼Ÿï¼ˆå¦‚ï¼š"æˆ‘æƒ³æ‰«æç«¯å£" â†’ ç«¯å£æ‰«æå·¥å…·ï¼‰
2. ç”¨æˆ·å¯èƒ½é‡åˆ°ä»€ä¹ˆé—®é¢˜éœ€è¦è¿™ä¸ª%sï¼Ÿï¼ˆå¦‚ï¼š"å¦‚ä½•è·å–åŸŸåIPï¼Ÿ" â†’ DNSæŸ¥è¯¢å·¥å…·ï¼‰
3. ç”¨æˆ·å¯èƒ½æœ‰ä»€ä¹ˆå®‰å…¨æµ‹è¯•éœ€æ±‚ï¼Ÿï¼ˆå¦‚ï¼š"æ£€æµ‹ç½‘ç«™æ¼æ´" â†’ æ¼æ´æ‰«æå·¥å…·ï¼‰
4. ä½¿ç”¨åœºæ™¯æè¿°ï¼ˆå¦‚ï¼š"éœ€è¦åˆ†æç½‘ç»œæµé‡" â†’ PCAPåˆ†æå·¥å…·ï¼‰

é—®é¢˜åº”è¯¥è¦†ç›–ï¼š
- åœºæ™¯æ„å›¾æè¿°ï¼ˆ"æˆ‘æƒ³è¦..."ã€"éœ€è¦..."ï¼‰
- åŠŸèƒ½æŸ¥è¯¢ï¼ˆ"æœ‰ä»€ä¹ˆå·¥å…·å¯ä»¥..."ã€"æœ‰ä»€ä¹ˆ Forge å¯ä»¥..."ï¼‰
- é—®é¢˜è§£å†³ï¼ˆ"å¦‚ä½•..."ã€"æ€ä¹ˆ..."ï¼‰
- å·¥å…·æ¨èï¼ˆ"ç”¨ä»€ä¹ˆå·¥å…·..."ã€"æ¨èä¸€ä¸ª..."ï¼‰
`, itemTypeCN, itemTypeCN, itemTypeCN)

        // ä½¿ç”¨ BuildSearchIndexKnowledge æ„å»ºæœç´¢ç´¢å¼•
        // ä¼ å…¥ search_type å’Œ search_target ä½œä¸ºçŸ¥è¯†æ¡ç›®çš„å…ƒæ•°æ®
        // search_type: AIå·¥å…·/Forge ç±»å‹ï¼Œsearch_target: å·¥å…·/Forge åç§°
        // ä½¿ç”¨ noPotentialQuestions å‹ç¼©å­˜å‚¨å¤§å°
        log.info("   ğŸ¤– Step 2: Calling AI to generate search questions...")
        searchTypeDesc = itemTypeCN  // "Yaklang AI å·¥å…·" æˆ– "Yaklang AI Forge"
        searchResult, buildErr = rag.BuildSearchIndexKnowledge(
            ragCollectionName, 
            itemDescription, 
            rag.extraPrompt(aiCapabilityExtraPrompt),
            rag.setSearchMeta(searchTypeDesc, itemName),
            rag.noPotentialQuestions()
        )
        if buildErr != nil {
            log.error("   âŒ Failed to build search index: %v", buildErr)
            log.error("   âŒ Error details: item=%s, type=%s, desc_len=%d", itemName, itemType, len(itemDescription))
            result["error"] = buildErr
            resultsChan <- result
            return
        }

        // æ‰“å°ç”Ÿæˆçš„é—®é¢˜
        questionsGenerated = len(searchResult.Questions)
        log.info("   âœ… Step 3: AI generated %d question indexes", questionsGenerated)
        log.info("   ğŸ“‹ Knowledge Entry ID: %s", searchResult.EntryID)
        log.info("   ğŸ“š Generated questions:")
        for i, q := range searchResult.Questions {
            log.info("      ğŸ”¸ Q%d: %s", i+1, q)
        }

        // æ›´æ–°å…¨å±€è®¡æ•°
        questionsMutex.Lock()
        totalQuestions += questionsGenerated
        questionsMutex.Unlock()

        log.info("   âœ“ Successfully indexed %s: %s (entry_id: %s)", itemType, itemName, searchResult.EntryID)
        
        result["success"] = true
        result["questions_generated"] = questionsGenerated
        result["entry_id"] = searchResult.EntryID

    } catch processErr {
        log.error("   âŒ Unexpected error: %v", processErr)
        result["error"] = sprintf("%v", processErr)
    }

    resultsChan <- result
}

// =============================================================================
// å¹¶å‘å¤„ç† AI èƒ½åŠ›é¡¹ç›®
// =============================================================================

log.info("")
log.info("=== Processing AI Capabilities (Concurrent, max %d) ===", maxConcurrency)

// å¯åŠ¨å¹¶å‘å¤„ç†
for i, itemInfo := range allItems {
    wg.Add(1)
    go processItem(i+1, totalCount, itemInfo)
}

// ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
wg.Wait()
close(resultsChan)

// æ”¶é›†ç»“æœ
successCount = 0
failedCount = 0
failedItems = []
successfulTools = 0
successfulForges = 0
totalQuestionsFromResults = 0

for result := range resultsChan {
    if result["success"] {
        successCount++
        totalQuestionsFromResults += result["questions_generated"]
        if result["type"] == "tool" {
            successfulTools++
        } else {
            successfulForges++
        }
    } else {
        failedCount++
        failedItems = append(failedItems, sprintf("%s (%s)", result["name"], result["type"]))
    }
}

log.info("")
log.info("=== Processing Results ===")
log.info("ğŸ“Š Total new items: %d", totalCount)
log.info("   ğŸ”§ Tools: %d (success: %d)", toolCount, successfulTools)
log.info("   ğŸ”¨ Forges: %d (success: %d)", forgeCount, successfulForges)
log.info("âœ“ Total successful: %d", successCount)
log.info("âœ— Total failed: %d", failedCount)
log.info("ğŸ“š Total questions generated: %d", totalQuestions)

if incrementalMode {
    log.info("")
    log.info("=== Incremental Update Summary ===")
    log.info("   ğŸ“Š Previously indexed: %d documents", existingDocCount)
    log.info("   âœ“ Skipped (already exists): Tools=%d, Forges=%d", toolExistsCount, forgeExistsCount)
    log.info("   â• Newly added: %d items", successCount)
}

if failedCount > 0 {
    log.warn("Failed items:")
    for i, itemName := range failedItems {
        log.warn("  %d. %s", i+1, itemName)
    }
}

// =============================================================================
// è·å–æœ€ç»ˆæ–‡æ¡£æ•°é‡
// =============================================================================

log.info("")
log.info("=== Final Statistics ===")

finalDocCount = 0
try {
    finalDocCount, _ = ragSystem.CountDocuments()
    log.info("ğŸ“Š Final document count: %d", finalDocCount)
    if incrementalMode {
        log.info("   - Previous documents: %d", existingDocCount)
        log.info("   - New documents added: %d", finalDocCount - existingDocCount)
    } else {
        log.info("   - Knowledge entries: %d", successCount)
        log.info("   - Question indexes: %d", totalQuestions)
    }
} catch countErr {
    log.warn("âš ï¸  Failed to get document count: %v", countErr)
}

// =============================================================================
// å¯¼å‡º RAG æ–‡ä»¶
// =============================================================================

log.info("")
log.info("=== Exporting RAG File ===")

try {
    err = rag.Export(ragCollectionName, finalOutputPath)
    if err != nil {
        log.error("âŒ Failed to export RAG file: %v", err)
        die(sprintf("Failed to export RAG file: %v", err))
    }

    if !file.IsExisted(finalOutputPath) {
        log.error("âŒ Export succeeded but file does not exist: %s", finalOutputPath)
        die("Failed to verify exported RAG file")
    }

    fileInfo = file.Stat(finalOutputPath)~
    fileSize = fileInfo.Size()

    log.info("âœ“ RAG file exported: %s", finalOutputPath)
    log.info("   ğŸ“ File size: %d bytes (%.2f MB)", fileSize, float64(fileSize)/1024/1024)

} catch exportErr {
    log.error("âŒ Failed to export RAG file: %v", exportErr)
    die(sprintf("Failed to export RAG file: %v", exportErr))
}

// =============================================================================
// ç”Ÿæˆæ„å»ºæŠ¥å‘Š
// =============================================================================

log.info("")
log.info("=== Generating Build Report ===")

reportPath = str.Replace(finalOutputPath, ".rag", ".build-report.md", 1)

report = sprintf("# AI èƒ½åŠ›æœç´¢ç´¢å¼•æ„å»ºæŠ¥å‘Š\n\n")
report += sprintf("**æ„å»ºæ—¶é—´**: %s\n\n", time.Now().Format("2006-01-02 15:04:05"))
report += sprintf("**Yak ç‰ˆæœ¬**: %s\n\n", yakVersion)
report += sprintf("**RAG æ–‡ä»¶**: %s\n\n", finalOutputPath)
report += sprintf("**é›†åˆåç§°**: %s\n\n", ragCollectionName)
report += sprintf("**æ„å»ºæ¨¡å¼**: %s\n\n", incrementalMode ? "å¢é‡æ›´æ–°" : "å…¨é‡æ„å»º")

report += "## ç´¢å¼•ç»“æ„\n\n"
report += "æœ¬ç´¢å¼•é‡‡ç”¨ **çŸ¥è¯†æ¡ç›® -> å¤šé—®é¢˜ç´¢å¼•** çš„ç»“æ„ï¼š\n\n"
report += "- **çŸ¥è¯†æ¡ç›® (knowledge_entry)**: å­˜å‚¨å·¥å…·/Forgeçš„å®Œæ•´æè¿°ä¿¡æ¯\n"
report += "- **é—®é¢˜ç´¢å¼• (question_index)**: æ¯ä¸ªçŸ¥è¯†æ¡ç›®å¯¹åº”å¤šä¸ªæœç´¢é—®é¢˜\n"
report += "- é—®é¢˜ç´¢å¼•é€šè¿‡ `entry_id` å…³è”åˆ°çŸ¥è¯†æ¡ç›®\n\n"

report += "## æ•°æ®æ¥æº\n\n"
report += "æœ¬ç´¢å¼•åŒ…å«ä»¥ä¸‹ä¸¤ç±» AI èƒ½åŠ›ï¼š\n\n"
report += sprintf("- **AI Tools** (`db.YieldAllAITools()`): %d ä¸ªæ–°å¢\n", toolCount)
report += sprintf("- **AI Forges** (`db.YieldAllAIForges()`): %d ä¸ªæ–°å¢\n\n", forgeCount)

if incrementalMode {
    report += "## å¢é‡æ›´æ–°ç»Ÿè®¡\n\n"
    report += sprintf("| æŒ‡æ ‡ | æ•°å€¼ |\n")
    report += sprintf("|------|------|\n")
    report += sprintf("| åŸæœ‰æ–‡æ¡£æ•° | %d |\n", existingDocCount)
    report += sprintf("| è·³è¿‡å·²å­˜åœ¨çš„ Tools | %d |\n", toolExistsCount)
    report += sprintf("| è·³è¿‡å·²å­˜åœ¨çš„ Forges | %d |\n", forgeExistsCount)
    report += sprintf("| æ–°å¢ Tools | %d |\n", toolCount)
    report += sprintf("| æ–°å¢ Forges | %d |\n", forgeCount)
    report += sprintf("| æ–°å¢æˆåŠŸ | %d |\n", successCount)
    report += sprintf("| æ–°å¢å¤±è´¥ | %d |\n", failedCount)
    report += sprintf("| æœ€ç»ˆæ–‡æ¡£æ•° | %d |\n\n", finalDocCount)
} else {
    report += "## æ„å»ºç»Ÿè®¡\n\n"
    report += sprintf("| æŒ‡æ ‡ | æ•°å€¼ |\n")
    report += sprintf("|------|------|\n")
    report += sprintf("| AI Tools æ€»æ•° | %d |\n", toolCount)
    report += sprintf("| AI Forges æ€»æ•° | %d |\n", forgeCount)
    report += sprintf("| æ€»å¤„ç†é¡¹ç›® | %d |\n", totalCount)
    report += sprintf("| æˆåŠŸå¤„ç† | %d |\n", successCount)
    report += sprintf("| å¤„ç†å¤±è´¥ | %d |\n", failedCount)
    report += sprintf("| çŸ¥è¯†æ¡ç›®æ•° | %d |\n", successCount)
    report += sprintf("| é—®é¢˜ç´¢å¼•æ•° | %d |\n", totalQuestions)
    report += sprintf("| æ€»æ–‡æ¡£æ•° | %d |\n\n", finalDocCount)
}

if failedCount > 0 {
    report += "## å¤„ç†å¤±è´¥çš„é¡¹ç›®\n\n"
    for i, itemName := range failedItems {
        report += sprintf("%d. %s\n", i+1, itemName)
    }
    report += "\n"
}

report += "## è¿‡æ»¤è§„åˆ™\n\n"
report += "ä»¥ä¸‹ç±»å‹çš„å·¥å…·/Forge è¢«è‡ªåŠ¨è¿‡æ»¤ï¼š\n\n"
report += "- åç§°ä»¥ `mock_` å¼€å¤´\n"
report += "- åç§°åŒ…å« `mock`\n"
report += "- åç§°ä¸º `sleep` æˆ–ä»¥ `sleep_` å¼€å¤´\n"
report += "- åç§°ä»¥ `test_` å¼€å¤´\n"
report += "- åç§°åŒ…å« `test`\n\n"

report += "## å¢é‡æ›´æ–°æœºåˆ¶\n\n"
report += "å½“ RAG æ–‡ä»¶å·²å­˜åœ¨æ—¶ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨è¿›å…¥å¢é‡æ›´æ–°æ¨¡å¼ï¼š\n\n"
report += "1. å¯¼å…¥ç°æœ‰çš„ RAG æ–‡ä»¶åˆ°å†…å­˜\n"
report += "2. å¯¹æ¯ä¸ªå¾…å¤„ç†çš„å·¥å…·/Forgeï¼Œä½¿ç”¨æ¨¡ç³Šæœç´¢æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨\n"
report += "3. å¦‚æœ `search_target` å…ƒæ•°æ®ä¸åç§°åŒ¹é…ï¼Œåˆ™è·³è¿‡è¯¥æ¡ç›®\n"
report += "4. åªæ·»åŠ æ–°çš„æ¡ç›®ï¼ŒèŠ‚çœ AI è°ƒç”¨æˆæœ¬\n\n"
report += "ä½¿ç”¨ `--force` å‚æ•°å¯å¼ºåˆ¶å…¨é‡é‡å»ºã€‚\n\n"

report += "## æœç´¢è¯´æ˜\n\n"
report += "æœç´¢æ—¶ï¼Œç³»ç»Ÿä¼šï¼š\n\n"
report += "1. é€šè¿‡é—®é¢˜ç´¢å¼•è¿›è¡Œè¯­ä¹‰æœç´¢\n"
report += "2. æ‰¾åˆ°åŒ¹é…çš„é—®é¢˜åï¼Œé€šè¿‡ `entry_id` è·å–å¯¹åº”çš„çŸ¥è¯†æ¡ç›®\n"
report += "3. è¿”å›å®Œæ•´çš„å·¥å…·/Forgeä¿¡æ¯\n\n"

report += "### Metadata å­—æ®µè¯´æ˜\n\n"
report += "| å­—æ®µ | è¯´æ˜ |\n"
report += "|------|------|\n"
report += "| `index_type` | æ–‡æ¡£ç±»å‹ï¼š`knowledge_entry` æˆ– `question_index` |\n"
report += "| `entry_id` | çŸ¥è¯†æ¡ç›®çš„å”¯ä¸€æ ‡è¯†ç¬¦ |\n"
report += "| `question_index` | é—®é¢˜æ–‡æœ¬ï¼ˆä»… question_index ç±»å‹æœ‰ï¼‰ |\n"
report += "| `search_type` | èƒ½åŠ›ç±»å‹æè¿°ï¼š`Yaklang AI å·¥å…·` æˆ– `Yaklang AI Forge` |\n"
report += "| `search_target` | å·¥å…·/Forge åç§°ï¼ˆç”¨äºå¢é‡æ›´æ–°æ—¶çš„å»é‡æ£€æŸ¥ï¼‰ |\n"

// ä¿å­˜æŠ¥å‘Š
file.Save(reportPath, report)~
log.info("âœ“ Build report generated: %s", reportPath)

// =============================================================================
// æœ€ç»ˆæ€»ç»“
// =============================================================================

log.info("")
log.info("=== Build Complete ===")
log.info("âœ“ AI Capabilities search index built successfully")
log.info("   ğŸ“ RAG File: %s", finalOutputPath)
log.info("   ğŸ“„ Report: %s", reportPath)
log.info("   ğŸ“Š Items: %d processed (%d tools, %d forges)", successCount, successfulTools, successfulForges)
log.info("   ğŸ“š Questions: %d generated", totalQuestions)
if incrementalMode {
    log.info("   ğŸ”„ Mode: Incremental update")
    log.info("   â­ï¸  Skipped: %d already indexed", toolExistsCount + forgeExistsCount)
}
log.info("")
log.info("ğŸ” To search the index, run:")
log.info("   go run common/yak/cmd/yak.go scripts/search-aitool-search-index.yak --rag-file %s --query \"your query\"", finalOutputPath)

if failedCount > 0 {
    os.Exit(1)
} else {
    os.Exit(0)
}

